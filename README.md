# ğŸ“„ Intelligent Document Section Extractor

This project extracts and prioritizes relevant sections from PDFs based on a defined **persona** and **job-to-be-done**. It processes multiple PDFs offline and outputs a clean, structured JSON format. Ideal for intelligent document understanding, search indexing, and summarization tasks.

---

## ğŸš€ Features

- âœ… **Extracts Title & Hierarchical Headings** (H1, H2, H3)
- âœ… **Filters Relevant Sections** based on persona + task
- âœ… **Summarizes Sections** using transformer-based models
- âœ… **Fully Offline** execution (no internet or GPU needed)
- âœ… **Dockerized** (for AMD64 CPUs, portable)
- âœ… Processes **multiple PDFs** in one go

---

## ğŸ§± Project Structure

```
.
â”œâ”€â”€ main.py                      # Pipeline entry point
â”œâ”€â”€ sample_input.json           # Input JSON: PDF paths + persona/task
â”œâ”€â”€ output.json                 # Final output JSON
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile                  # Offline build environment
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ utils/
    â”œâ”€â”€ pdf_parser.py           # Extracts title and section headings
    â”œâ”€â”€ filter.py               # Filters sections based on relevance
    â”œâ”€â”€ summarizer.py           # Summarizes selected sections
```

---

## ğŸ“¥ Sample Input (sample_input.json)

```json
{
  "persona": "Product Manager",
  "task": "Wants to understand how the product roadmap is structured",
  "pdf_paths": ["docs/product_strategy.pdf", "docs/internal_roadmap.pdf"]
}
```

---

## ğŸ“¤ Output Format (output.json)

```json
{
  "docs/product_strategy.pdf": [
    {
      "heading": "Product Roadmap Overview",
      "page": 5,
      "content": "Summarized or filtered content based on the persona and task..."
    },
    ...
  ]
}
```

---

## ğŸ³ Run with Docker

### Step 1: Build the Docker image

```bash
docker build -t pdf-extractor .
```

### Step 2: Run the extractor

```bash
docker run --rm -v $(pwd):/app pdf-extractor
```

> This mounts your current directory inside the container to read input and write output.

---

## ğŸ› ï¸ Tech Stack

| Library               | Purpose                          |
|----------------------|----------------------------------|
| **pdfplumber==0.10.2**         | Extracts text + structured layout from PDF |
| **PyMuPDF==1.23.4**            | Fine-grained PDF parsing (e.g., fonts, layout) |
| **sentence-transformers==2.2.2** | Semantic similarity & summaries |
| **scikit-learn==1.3.2**        | Cosine similarity, preprocessing |
| **nltk==3.8.1**                | Tokenization, text cleaning |
| **numpy==1.26.4**              | Numerical operations |
| **pandas==2.2.2**              | Data manipulation |
| **jsonlines==4.0.0**           | JSONL file support |
| **python-dotenv==1.0.1**       | Load environment variables |
| **huggingface_hub==0.14.1**    | Model loading (runs offline) |

---

## âš™ï¸ Requirements

- Docker (preferred)
- Or install manually with:

```bash
pip install -r requirements.txt
```

---

## ğŸ“Œ Constraints & Performance

- ğŸ§  **CPU-only**, No GPU needed
- ğŸš« **Offline-first** (no internet calls)
- â±ï¸ **< 10 seconds** per PDF (~50 pages)
- ğŸ“¦ **Model & dependencies under 200MB**

---

## ğŸ§  How It Works (Pipeline)

1. `main.py` reads `sample_input.json`
2. For each PDF:
   - `pdf_parser.py` extracts section headings and text
   - `filter.py` ranks sections based on persona/task relevance
   - `summarizer.py` optionally condenses content
3. Outputs structured sections to `output.json`

---

## ğŸ“ƒ License

For hackathon/demo purposes only. Not production-ready.
